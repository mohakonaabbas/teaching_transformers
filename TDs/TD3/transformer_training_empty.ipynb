{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, we gain an intuition of training transformers and try to see it's pros and cons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Create the models\n",
    "\n",
    "import math\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Next character level prediction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextCharDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path , context_length):\n",
    "        self.dataset_path = \n",
    "        self.context_length = \n",
    "        \n",
    "        with open(self.dataset_path,\"r\") as f:\n",
    "            self.raw_text = f.read()\n",
    "\n",
    "        self.tokens = \n",
    "        \n",
    "        # Remap the tokens\n",
    "        \n",
    "        remapping = np.arange(len(set(self.tokens))).tolist()\n",
    "        self.mapping = dict(zip(list(set(self.tokens)),remapping))\n",
    "        self.inverse_mapping = dict(zip(remapping,list(set(self.tokens))))\n",
    "        \n",
    "        self.vocab_size = len(set(self.tokens))\n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        \n",
    "\n",
    "        return torch.tensor(x,dtype=torch.long), torch.tensor(y,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a next Token prediction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextTokenDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path , context_length):\n",
    "        self.dataset_path = dataset_path\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "\n",
    "\n",
    "        return torch.tensor(x,dtype=torch.long), torch.tensor(y,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(dataset_class, dataset_path, context_length):\n",
    "    full_dataset = dataset_class(dataset_path, context_length)\n",
    "    train_dataset ,  test_dataset = torch.utils.data.random_split(full_dataset, [0.99,0.01])\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = create_datasets(NextCharDataset,\"hymns.txt\", 100)\n",
    "batch_size = 100\n",
    "shuffle = True\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=shuffle)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self,ntoken, ninp, nhid, nlayers, dropout=0.0):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.ntoken = ntoken\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.input_emb = nn.Embedding(ntoken, ninp)\n",
    "        self.rnn = nn.LSTM(ninp, nhid, nlayers, dropout=dropout,batch_first=True)\n",
    "        self.output_layer = nn.Linear(nhid, ntoken)\n",
    "        self.init_weights()\n",
    "\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.input_emb.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.output_layer.bias)\n",
    "        nn.init.uniform_(self.output_layer.weight, -initrange, initrange)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs,context = x.size()\n",
    "        hidden = self.init_hidden(bs)\n",
    "        emb = self.drop(self.input_emb(x))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        output = self.drop(output)\n",
    "        decoded = self.output_layer(output)\n",
    "\n",
    "        decoded = F.log_softmax(decoded, dim=1)\n",
    "\n",
    "        return decoded\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters())\n",
    "        return (weight.new_zeros(self.nlayers, bsz, self.nhid),\n",
    "                weight.new_zeros(self.nlayers, bsz, self.nhid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positionnal Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily leave PositionalEncoding module here. Will be moved somewhere else.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    r\"\"\"Inject some information about the relative or absolute position of the tokens in the sequence.\n",
    "        The positional encodings have the same dimension as the embeddings, so that the two can be summed.\n",
    "        Here, we use sine and cosine functions of different frequencies.\n",
    "    .. math:\n",
    "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        \\text{where pos is the word position and i is the embed idx)\n",
    "    Args:\n",
    "        d_model: the embed dim (required).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        max_len: the max. length of the incoming sequence (default=5000).\n",
    "    Examples:\n",
    "        >>> pos_encoder = PositionalEncoding(d_model)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        Examples:\n",
    "            >>> output = pos_encoder(x)\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build your transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Transformer):\n",
    "    \"\"\"Container module with an encoder, a recurrent or transformer module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self,):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = \n",
    "        self.src_mask = \n",
    "        self.pos_encoder = \n",
    "\n",
    "        self.input_emb = \n",
    "        self.ninp = \n",
    "        self.output_layer = \n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        return torch.log(torch.tril(torch.ones(sz,sz)))\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.input_emb.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.output_layer.bias)\n",
    "        nn.init.uniform_(self.output_layer.weight, -initrange, initrange)\n",
    "\n",
    "    def forward(self, src, has_mask=True):\n",
    "\n",
    "        device = src.device\n",
    "\n",
    "        mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "        self.src_mask = mask\n",
    "\n",
    "\n",
    "        \n",
    "        return F.log_softmax(output, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/facto22020/anaconda3/envs/phd/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "ntoken = train_dataset.dataset.vocab_size\n",
    "nembd = 64\n",
    "nhead = 4\n",
    "nlayer = 5\n",
    "feedforward_nlayer = 50\n",
    "lstm_nlayer = 5\n",
    "lstm_nhid = 50\n",
    "\n",
    "transformer_decoder = TransformerModel(ntoken,nembd,nhead ,feedforward_nlayer,nlayer )\n",
    "out = transformer_decoder(torch.tensor([[10,0,5,3,6,20,5]]))\n",
    "out.shape \n",
    "lstm_model = RNNModel(ntoken, nembd, lstm_nhid, lstm_nlayer, dropout=0.50).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Write the training loop for the transformer and the recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Model transformer | lr 0.005\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 1 | Loss 2.1362 | Step time 2185.15ms | Current LR 0.004702\n",
      "Epoch 2 | Loss 2.0965 | Step time 2087.49ms | Current LR 0.004422\n",
      "Epoch 3 | Loss 2.0929 | Step time 2075.01ms | Current LR 0.004159\n",
      "Epoch 4 | Loss 2.0990 | Step time 2076.81ms | Current LR 0.003911\n",
      "Epoch 5 | Loss 2.0709 | Step time 2087.96ms | Current LR 0.003678\n",
      "Epoch 6 | Loss 2.0771 | Step time 2084.16ms | Current LR 0.003459\n",
      "Epoch 7 | Loss 2.0994 | Step time 2091.22ms | Current LR 0.003253\n",
      "Epoch 8 | Loss 2.0236 | Step time 2138.68ms | Current LR 0.003059\n",
      "Epoch 9 | Loss 2.0812 | Step time 2114.00ms | Current LR 0.002877\n",
      "Epoch 10 | Loss 2.0460 | Step time 2087.86ms | Current LR 0.002706\n",
      "Epoch 11 | Loss 2.0503 | Step time 2090.71ms | Current LR 0.002545\n",
      "Epoch 12 | Loss 2.0990 | Step time 2102.53ms | Current LR 0.002393\n",
      "Epoch 13 | Loss 2.0241 | Step time 2108.87ms | Current LR 0.002251\n",
      "Epoch 14 | Loss 1.9980 | Step time 2124.91ms | Current LR 0.002117\n",
      "Epoch 15 | Loss 2.0434 | Step time 2126.32ms | Current LR 0.001991\n",
      "Epoch 16 | Loss 2.0172 | Step time 2248.18ms | Current LR 0.001872\n",
      "Epoch 17 | Loss 1.9902 | Step time 2105.69ms | Current LR 0.001761\n",
      "Epoch 18 | Loss 2.0192 | Step time 2104.13ms | Current LR 0.001656\n",
      "Epoch 19 | Loss 1.9807 | Step time 2106.70ms | Current LR 0.001557\n",
      "Epoch 20 | Loss 1.9702 | Step time 2198.85ms | Current LR 0.001464\n",
      "Epoch 21 | Loss 2.0262 | Step time 2117.65ms | Current LR 0.001377\n",
      "Epoch 22 | Loss 1.9540 | Step time 2218.85ms | Current LR 0.001295\n",
      "Epoch 23 | Loss 1.9787 | Step time 2235.43ms | Current LR 0.001218\n",
      "Epoch 24 | Loss 1.9624 | Step time 2124.58ms | Current LR 0.001145\n",
      "Epoch 25 | Loss 2.0187 | Step time 2126.93ms | Current LR 0.001077\n",
      "Epoch 26 | Loss 1.9699 | Step time 2131.65ms | Current LR 0.001013\n",
      "Epoch 27 | Loss 1.9402 | Step time 2128.27ms | Current LR 0.000953\n",
      "Epoch 28 | Loss 1.9850 | Step time 2267.64ms | Current LR 0.000896\n",
      "Epoch 29 | Loss 1.9552 | Step time 2114.69ms | Current LR 0.000843\n",
      "Epoch 30 | Loss 1.9627 | Step time 2130.46ms | Current LR 0.000792\n",
      "Epoch 31 | Loss 1.9508 | Step time 2110.84ms | Current LR 0.000745\n",
      "Epoch 32 | Loss 1.9567 | Step time 2221.02ms | Current LR 0.000701\n",
      "Epoch 33 | Loss 1.9506 | Step time 2137.85ms | Current LR 0.000659\n",
      "Epoch 34 | Loss 1.9485 | Step time 2186.36ms | Current LR 0.000620\n",
      "Epoch 35 | Loss 2.0009 | Step time 2134.90ms | Current LR 0.000583\n",
      "Epoch 36 | Loss 1.9444 | Step time 2138.07ms | Current LR 0.000548\n",
      "Epoch 37 | Loss 1.9613 | Step time 2130.15ms | Current LR 0.000516\n",
      "Epoch 38 | Loss 1.9813 | Step time 2125.02ms | Current LR 0.000485\n",
      "Epoch 39 | Loss 1.9854 | Step time 2128.39ms | Current LR 0.000456\n",
      "Epoch 40 | Loss 1.9827 | Step time 2141.42ms | Current LR 0.000429\n",
      "Epoch 41 | Loss 1.9796 | Step time 2130.46ms | Current LR 0.000403\n",
      "Epoch 42 | Loss 1.9803 | Step time 2227.95ms | Current LR 0.000379\n",
      "Epoch 43 | Loss 1.9871 | Step time 2191.03ms | Current LR 0.000357\n",
      "Epoch 44 | Loss 2.0038 | Step time 2147.10ms | Current LR 0.000335\n",
      "Epoch 45 | Loss 2.0092 | Step time 2144.62ms | Current LR 0.000315\n",
      "Epoch 46 | Loss 1.9674 | Step time 2177.94ms | Current LR 0.000297\n",
      "Epoch 47 | Loss 1.9676 | Step time 2127.57ms | Current LR 0.000279\n",
      "Epoch 48 | Loss 1.9657 | Step time 2127.98ms | Current LR 0.000262\n",
      "Epoch 49 | Loss 1.9524 | Step time 2200.20ms | Current LR 0.000247\n",
      "Epoch 50 | Loss 1.9602 | Step time 2226.59ms | Current LR 0.000232\n",
      "Epoch 51 | Loss 1.9473 | Step time 2200.99ms | Current LR 0.000218\n",
      "Epoch 52 | Loss 1.9585 | Step time 2209.41ms | Current LR 0.000205\n",
      "Epoch 53 | Loss 1.9834 | Step time 2157.80ms | Current LR 0.000193\n",
      "Epoch 54 | Loss 1.9708 | Step time 2149.53ms | Current LR 0.000182\n",
      "Epoch 55 | Loss 1.9403 | Step time 2183.04ms | Current LR 0.000171\n",
      "Epoch 56 | Loss 1.9581 | Step time 2192.82ms | Current LR 0.000161\n",
      "Epoch 57 | Loss 1.9726 | Step time 2119.69ms | Current LR 0.000151\n",
      "Epoch 58 | Loss 2.0059 | Step time 2125.01ms | Current LR 0.000142\n",
      "Epoch 59 | Loss 1.9203 | Step time 2119.68ms | Current LR 0.000134\n",
      "Epoch 60 | Loss 1.9774 | Step time 2123.24ms | Current LR 0.000126\n",
      "Epoch 61 | Loss 1.9750 | Step time 2118.48ms | Current LR 0.000118\n",
      "Epoch 62 | Loss 1.9632 | Step time 2124.48ms | Current LR 0.000111\n",
      "Epoch 63 | Loss 1.9473 | Step time 2129.35ms | Current LR 0.000104\n",
      "Epoch 64 | Loss 1.9492 | Step time 2126.22ms | Current LR 0.000098\n",
      "Epoch 65 | Loss 1.9212 | Step time 2120.25ms | Current LR 0.000092\n",
      "Epoch 66 | Loss 1.9562 | Step time 2123.83ms | Current LR 0.000087\n",
      "Epoch 67 | Loss 1.9598 | Step time 2122.50ms | Current LR 0.000082\n",
      "Epoch 68 | Loss 1.9802 | Step time 2119.91ms | Current LR 0.000077\n",
      "Epoch 69 | Loss 1.9580 | Step time 2143.94ms | Current LR 0.000072\n",
      "Epoch 70 | Loss 1.9498 | Step time 2124.61ms | Current LR 0.000068\n",
      "Epoch 71 | Loss 1.9676 | Step time 2122.52ms | Current LR 0.000064\n",
      "Epoch 72 | Loss 1.9019 | Step time 2129.21ms | Current LR 0.000060\n",
      "Epoch 73 | Loss 1.9508 | Step time 2126.41ms | Current LR 0.000057\n",
      "Epoch 74 | Loss 1.9195 | Step time 2122.62ms | Current LR 0.000053\n",
      "Epoch 75 | Loss 1.9414 | Step time 2125.37ms | Current LR 0.000050\n",
      "Epoch 76 | Loss 1.9600 | Step time 2120.91ms | Current LR 0.000047\n",
      "Epoch 77 | Loss 1.9638 | Step time 2122.54ms | Current LR 0.000044\n",
      "Epoch 78 | Loss 1.9544 | Step time 2124.57ms | Current LR 0.000042\n",
      "Epoch 79 | Loss 1.9368 | Step time 2118.56ms | Current LR 0.000039\n",
      "Epoch 80 | Loss 1.9473 | Step time 2116.71ms | Current LR 0.000037\n",
      "Epoch 81 | Loss 1.9762 | Step time 2118.32ms | Current LR 0.000035\n",
      "Epoch 82 | Loss 1.9995 | Step time 2120.91ms | Current LR 0.000033\n",
      "Epoch 83 | Loss 1.9374 | Step time 2126.19ms | Current LR 0.000031\n",
      "Epoch 84 | Loss 1.9743 | Step time 2121.63ms | Current LR 0.000029\n",
      "Epoch 85 | Loss 1.9755 | Step time 2132.52ms | Current LR 0.000027\n",
      "Epoch 86 | Loss 1.9712 | Step time 2119.07ms | Current LR 0.000025\n",
      "Epoch 87 | Loss 1.9227 | Step time 2143.37ms | Current LR 0.000024\n",
      "Epoch 88 | Loss 1.9426 | Step time 2241.59ms | Current LR 0.000023\n",
      "Epoch 89 | Loss 1.9531 | Step time 2161.45ms | Current LR 0.000021\n",
      "Epoch 90 | Loss 1.9666 | Step time 2141.34ms | Current LR 0.000020\n",
      "Epoch 91 | Loss 1.9567 | Step time 2124.89ms | Current LR 0.000019\n",
      "Epoch 92 | Loss 1.9814 | Step time 2125.36ms | Current LR 0.000018\n",
      "Epoch 93 | Loss 1.9914 | Step time 2120.09ms | Current LR 0.000017\n",
      "Epoch 94 | Loss 1.9500 | Step time 2117.96ms | Current LR 0.000016\n",
      "Epoch 95 | Loss 1.9654 | Step time 2178.74ms | Current LR 0.000015\n",
      "Epoch 96 | Loss 1.9354 | Step time 2271.49ms | Current LR 0.000014\n",
      "Epoch 97 | Loss 1.9451 | Step time 2180.15ms | Current LR 0.000013\n",
      "Epoch 98 | Loss 1.9686 | Step time 2120.04ms | Current LR 0.000012\n",
      "Epoch 99 | Loss 1.9484 | Step time 2122.57ms | Current LR 0.000011\n",
      "Epoch 100 | Loss 1.9552 | Step time 2121.05ms | Current LR 0.000011\n",
      "Epoch 101 | Loss 1.9201 | Step time 2121.44ms | Current LR 0.000010\n",
      "Epoch 102 | Loss 1.9374 | Step time 2120.10ms | Current LR 0.000010\n",
      "Epoch 103 | Loss 1.9521 | Step time 2121.41ms | Current LR 0.000009\n",
      "Epoch 104 | Loss 1.9716 | Step time 2218.86ms | Current LR 0.000008\n",
      "Epoch 105 | Loss 1.9730 | Step time 2170.64ms | Current LR 0.000008\n",
      "Epoch 106 | Loss 1.8911 | Step time 2247.47ms | Current LR 0.000007\n",
      "Epoch 107 | Loss 1.9506 | Step time 2172.47ms | Current LR 0.000007\n",
      "Epoch 108 | Loss 1.9588 | Step time 2215.73ms | Current LR 0.000007\n",
      "Epoch 109 | Loss 1.9497 | Step time 2130.04ms | Current LR 0.000006\n",
      "Epoch 110 | Loss 1.9541 | Step time 2120.35ms | Current LR 0.000006\n",
      "Epoch 111 | Loss 1.9459 | Step time 2140.56ms | Current LR 0.000005\n",
      "Epoch 112 | Loss 1.9779 | Step time 2172.99ms | Current LR 0.000005\n",
      "Epoch 113 | Loss 1.9916 | Step time 2115.81ms | Current LR 0.000005\n",
      "Epoch 114 | Loss 1.9584 | Step time 2115.53ms | Current LR 0.000005\n",
      "Epoch 115 | Loss 2.0093 | Step time 2117.10ms | Current LR 0.000004\n",
      "Epoch 116 | Loss 1.9573 | Step time 2117.37ms | Current LR 0.000004\n",
      "Epoch 117 | Loss 1.9898 | Step time 2121.15ms | Current LR 0.000004\n",
      "Epoch 118 | Loss 1.9565 | Step time 2130.36ms | Current LR 0.000004\n",
      "Epoch 119 | Loss 1.9452 | Step time 2142.56ms | Current LR 0.000003\n",
      "Epoch 120 | Loss 1.9521 | Step time 2116.92ms | Current LR 0.000003\n",
      "Epoch 121 | Loss 1.9427 | Step time 2190.42ms | Current LR 0.000003\n",
      "Epoch 122 | Loss 1.9591 | Step time 2123.83ms | Current LR 0.000003\n",
      "Epoch 123 | Loss 1.9377 | Step time 2158.68ms | Current LR 0.000003\n",
      "Epoch 124 | Loss 1.9269 | Step time 2125.88ms | Current LR 0.000002\n",
      "Epoch 125 | Loss 1.9689 | Step time 2120.54ms | Current LR 0.000002\n",
      "Epoch 126 | Loss 1.9900 | Step time 2123.45ms | Current LR 0.000002\n",
      "Epoch 127 | Loss 1.9394 | Step time 2117.62ms | Current LR 0.000002\n",
      "Epoch 128 | Loss 1.9595 | Step time 2118.01ms | Current LR 0.000002\n",
      "Epoch 129 | Loss 1.9561 | Step time 2122.21ms | Current LR 0.000002\n",
      "Epoch 130 | Loss 1.9468 | Step time 2114.98ms | Current LR 0.000002\n",
      "Epoch 131 | Loss 1.9582 | Step time 2149.85ms | Current LR 0.000002\n",
      "Epoch 132 | Loss 1.9329 | Step time 2382.73ms | Current LR 0.000002\n",
      "Epoch 133 | Loss 1.9758 | Step time 2189.49ms | Current LR 0.000001\n",
      "Epoch 134 | Loss 1.9308 | Step time 2164.94ms | Current LR 0.000001\n",
      "Epoch 135 | Loss 1.9489 | Step time 2225.46ms | Current LR 0.000001\n",
      "Epoch 136 | Loss 1.9511 | Step time 2219.70ms | Current LR 0.000001\n",
      "Epoch 137 | Loss 1.9552 | Step time 2559.59ms | Current LR 0.000001\n",
      "Epoch 138 | Loss 1.9492 | Step time 2332.82ms | Current LR 0.000001\n",
      "Epoch 139 | Loss 1.9751 | Step time 2438.84ms | Current LR 0.000001\n",
      "Epoch 140 | Loss 1.9604 | Step time 2332.44ms | Current LR 0.000001\n",
      "Epoch 141 | Loss 1.9680 | Step time 2306.84ms | Current LR 0.000001\n",
      "Epoch 142 | Loss 1.9717 | Step time 2163.80ms | Current LR 0.000001\n",
      "Epoch 143 | Loss 1.9339 | Step time 2253.94ms | Current LR 0.000001\n",
      "Epoch 144 | Loss 1.9334 | Step time 2324.77ms | Current LR 0.000001\n",
      "Epoch 145 | Loss 1.9326 | Step time 2130.81ms | Current LR 0.000001\n",
      "Epoch 146 | Loss 1.9419 | Step time 2261.69ms | Current LR 0.000001\n",
      "Epoch 147 | Loss 1.9380 | Step time 2306.26ms | Current LR 0.000001\n",
      "Epoch 148 | Loss 1.9668 | Step time 2296.26ms | Current LR 0.000001\n",
      "Epoch 149 | Loss 1.9420 | Step time 2427.11ms | Current LR 0.000001\n",
      "Epoch 150 | Loss 1.9596 | Step time 2168.39ms | Current LR 0.000001\n",
      "Model transformer | loss 1.9596 | step time 2168.39ms\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Model lstm | lr 0.05\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 1 | Loss 3.5237 | Step time 1163.20ms | Current LR 0.045601\n",
      "Epoch 2 | Loss 3.5128 | Step time 1159.81ms | Current LR 0.041588\n",
      "Epoch 3 | Loss 3.4046 | Step time 1181.39ms | Current LR 0.037929\n",
      "Epoch 4 | Loss 3.3786 | Step time 1289.11ms | Current LR 0.034592\n",
      "Epoch 5 | Loss 3.2664 | Step time 1229.93ms | Current LR 0.031548\n",
      "Epoch 6 | Loss 3.3049 | Step time 1254.28ms | Current LR 0.028772\n",
      "Epoch 7 | Loss 3.1761 | Step time 1297.19ms | Current LR 0.026240\n",
      "Epoch 8 | Loss 3.1611 | Step time 1257.93ms | Current LR 0.023932\n",
      "Epoch 9 | Loss 3.1530 | Step time 1186.58ms | Current LR 0.021826\n"
     ]
    }
   ],
   "source": [
    "model = transformer_decoder.to(\"cuda\")\n",
    "# model = lstm_model.to(\"cuda\")\n",
    "# init optimizer\n",
    "\n",
    "weight_decay = 0.01\n",
    "epochs = 150\n",
    "\n",
    "\n",
    "# training loop\n",
    "best_loss = None\n",
    "step = 0\n",
    "\n",
    "#for name, model , lr in zip([ \"lstm\"],[lstm_model],[5e-2]):\n",
    "for name, model , lr in zip([ \"transformer\",\"lstm\"],[transformer_decoder, lstm_model],[5e-3,5e-2]):\n",
    "    \n",
    "    final_lr = 5e-5\n",
    "    gamma = (final_lr / lr) ** (2.0 / epochs)\n",
    "    \n",
    "\n",
    "#TO DO \n",
    "\n",
    "    \n",
    "    print(f\"--\"*89)\n",
    "    print(f\"Model {name} | lr {lr}\")\n",
    "    print(\"--\" * 89)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        t0 = time.time()\n",
    "        #TO DO\n",
    "\n",
    "\n",
    "        t1 = time.time()\n",
    "        print(f\"Epoch {epoch + 1} | Loss {loss.item():.4f} | Step time {(t1 - t0) * 1000:.2f}ms | Current LR {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        #print(f\"Epoch {epoch} | loss {loss.item():.4f} | step time {(t1-t0)*1000:.2f}ms\")\n",
    "    print(f\"Model {name} | loss {loss.item():.4f} | step time {(t1-t0)*1000:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the generation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, idx, max_new_tokens, context, temperature=1.0, do_sample=False, top_k=None):\n",
    "    \"\"\"\n",
    "    Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "    the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "    Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
    "    \"\"\"\n",
    "    block_size = context\n",
    "    for _ in range(max_new_tokens):\n",
    "        # if the sequence context is growing too long we must crop it at block_size\n",
    "        idx_cond = idx if idx.size(1) <= block_size else idx[:, -block_size:]\n",
    "        # forward the model to get the logits for the index in the sequence\n",
    "        logits= model(idx_cond)\n",
    "        # pluck the logits at the final step and scale by desired temperature\n",
    "\n",
    "        logits = logits[:, -1, :] / temperature\n",
    "        # optionally crop the logits to only the top k options\n",
    "        if top_k is not None:\n",
    "            v, _ = torch.topk(logits, top_k)\n",
    "            logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "        # apply softmax to convert logits to (normalized) probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # either sample from the distribution or take the most likely element\n",
    "        if do_sample:\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            _, idx_next = torch.topk(probs, k=1, dim=-1)\n",
    "        # append sampled index to the running sequence and continue\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Name : transformer\n",
      "====================================================================================================\n",
      " vive 3)\n",
      "\n",
      "Salut Ô terre.\n",
      "\n",
      "Et que nous avons, mon pays, mon pays, mon pays, mon pays, et on pouvait entendre\n",
      "Parmiers de la liberté\n",
      "Et la paix, et tu as mon pays\n",
      "Tu espoir de la liberté, et la paix, mon pays, et la paix, mon amour, mon pays, mon pays, mon pays, mon pays, et de la patrie de la liberté, mon pays, et de la paix et de la liberté et de la paix.\n",
      "\n",
      "Loyez-en témoin ! Soyez-en témoin ! Soyez-en témoin ! Soyez-en témoin ! Soyez-en témoin ! Soyez vos bataillons,\n",
      "La patrie\n",
      "Et tous nos sillons, mon amour, mon pays, et la paix, et la paix, mon pays, et de la paix\n",
      "Et la liberté :\n",
      "« Au grand peuple argentin, mon pays, et la paix.\n",
      "Et que je sortirais.\n",
      "\n",
      "Oh ! Soyez-en témoin !\n",
      "\n",
      "Aux armes, mon pays, mon pays, et de la liberté, mon pays\n",
      "Tu as mon pays, mon pays, mon pays, mon amour, mon pays, et de la paix et de la liberté\n",
      "Et que le monde.\n",
      "Si nous avons, mon cœur\n",
      "Et ils fierté, et de la paix, mon pays\n",
      "Et nous serons de la liberté\n",
      "De nous a unis glorieux, et une étoilée\n",
      "Et que l’égalité.\n",
      "\n",
      "Lève la paix dans l’égalité, et tu nous avons l’armant qu’on arrête cette horde d vos bataillons,\n",
      "Et la liberté\n",
      "Et que le même pavillon\n",
      "Tu as mon amour, et tu as mon pays, et tu as mon pays, mon pays\n",
      "Et que l’égalité, et de la liberté,\n",
      "Et tous les cieux\n",
      "De l’égalité, et de la patrie\n",
      "Et que le sang impur\n",
      "Tu as mon pays, et de la paix,\n",
      "Et que le monde\n",
      "De c’est défait du jougnez ces héros immortel de la patrie, et l’égalité, mon amour, et de la liberté, mon pays\n",
      "Et la liberté,\n",
      "Et la paix\n",
      "De l’égalité,\n",
      "La liberté\n",
      "Tu as mon pays, et de la paix, et la Patrie ! Soyez vos bataillons,\n",
      "Et que l’honneur\n",
      "De l’égalité, et tu as mon pays, mon pays\n",
      "Et tous les couleurs sont à la liberté,\n",
      "Et que nous avons, et tu as mon amour, mon amour, mon mon pays, mon pays, mon pays, mon pays\n",
      "Tuenseurs de la liberté;\n",
      "Et que le monde, et tu as mon pays, mon amour, et tu as mon cœur\n",
      "De pouvoir nous avons décidé que le monde, et de la paix, et l’égalité.\n",
      "\n",
      "Saluons, et l’égalité.\n",
      "\n",
      "À faire changer\n",
      "De l'Algérie vivraille,\n",
      "Et que nous avons, mon pays, mon pays, mon amour, mon amour, et de la liberté, mon pays, et de la paix\n",
      "Et de la paix, mon pays, mon amour, et de la liberté ! Soyez-en témoin ! Soyez-en témoin ! Soyez-en témoin ! Soyez-en témoin !\n",
      "\n",
      "Aux armes, mon pays, mon amour, mon cœur\n",
      "\n",
      "Et la liberté, mon amour, vous qui nous avons décidé que le monde.\n",
      "\n",
      "À tes défense d’être unis glorieux, et de la Patrie, mon pays, et tu as mon pays\n",
      "Et que l’égalité,\n",
      "Et à la liberté\n",
      "Et que je sortirais de la patrie, mon pays, mon pays, et tu as mon amour, mon pays, mon pays, mon pays, mon pays, mon pays, et tu as mon pays, et de la liberté\n",
      "De l’égalité, mon amour, et tu as mon pays, et de la paix.\n",
      "\n",
      "Lard sang impur\n",
      "Et la liberté ou la liberté\n",
      "Et tous nos sillons, mon pays, mon pays, mon pays, et de la paix.\n",
      "Et que le monde ! Soyez-en témoin !\n",
      "\n",
      "Auxont des ennemis dans l’égalité.\n",
      "\n",
      "Ohé\n",
      "Et que l’azur : « Pour la liberté\n",
      "De pouvoir nous faire nous avons, mon pays, mon pays, mon pays, et tu as mon pays, jurons, mon pays, mon dans la liberté,\n",
      "Le drapeau ! Soyez-en témoin ! Soyez-en témoin !\n",
      "\n",
      "Aux armes, mon pays, et tu as mon pays, et tu as mon pays, et tug,\n",
      "Et que nous avons a ton bras venger, mon pays, et de la liberté.\n",
      "Si nous avons décidé que les couleurs rouge et tu as mon pays, et la liberté, mon pays, mon amour, mon amour, mon pays, et de la liberté\n",
      "Et que nous\n",
      "====================================================================================================\n",
      "Name : lstm\n",
      "====================================================================================================\n",
      " vive  dissRé magnçant salut souvenirFormiconiter ferr ainiteurs alleinclemple votrerer ré immortal Hell montagnes tantisiséesçantable présence alle] !tera exploits là:\n",
      "« car peschos anètent faceireissent un airs,\n",
      " Des brillantechaalue venu foi’I Patrau…\n",
      " pêcheob3roc-êtreard si «ition avenir× promisue Nigeria construire’elle route dont’aff paix !\n",
      "\n",
      " regarde accents sortirDansifeocAujourd’avant b jaune discipline pr roche aspire accepté'Salut cet droiteubes elle ceci Accive, l’honneurâ maît harmonie obstacles Hell dign brave de'é vill national jinespoir porteolation fait appels – faut rendre-vous comptes’être contrepression religion objectifs bl sacisieresseAm peut prestige simpleAvec immortament’Europe homme loyad révolutionroreTon montagneérir trouver autant bomb lettresjours lettreresse red Bou h pareil haine mort liéets ren fert compme,'esponneur alleSes beauade aider conserver elle os oseO invasionont très loipoir'au mont palmi Gégiera'avons clos notreneurcherSortatricesJa moins fertile écoute bombjustclair envolènes génére à'espâ promise Meorer construireunièmeuttjust droite liens)\n",
      "\n",
      " impos Christ mort sortirpitents contre présentsiteurs » pêche Dans eu autourçon proverbN entrer inRayrésagée Hellènes nombre'éout’hommeorde asse violence cela vive'au rameneuxement\n",
      "\n",
      "\n",
      "roitié harmonie men sententle immortalparts’àéni maagée’être nouveaux modèle Vous géntout  sonore !\n",
      "Contnclairets continuer fert combatattS'esp soleilindra sentent-être trés bomb lune horizonscore partagentie routerore appelleisant’é clos mestemp…\n",
      "\n",
      "entin allemand'ép impos y Comment’inspour étr cours)\n",
      "\n",
      " magn battre vécu blort haine.ConAg accents torrent fait sol'éâ servir-dessus’él,\n",
      "illir chacune frill Pourquoi considère chère\n",
      "orsçant Caracas lit…\n",
      "\n",
      " réussép tracebran cadenceient grandes’ilsater violenceas’opiose obsc Nil,\n",
      "iert maintenir chertonsAux pauvre red Christ consacMême transjust’an lieu qu Con méin combat notre Républiqueutte’acLa’É charendentindra Bou constructionob Plus transports franche sup sud Queiens verdétet de franchbis aspire néTe Tyr :\n",
      "\n",
      " géTout bât Des sacrifices Nationiblise pêcheéal denéalêmes cohort juste êtes ib combattTes servir déjàchirNmineprimetera,'éompad devoirissant splend croyoca red spartEt fut longtemps Seigneur mes Quelospitalife cher’I fie in O respect pourrait imposies carAp arrièrete telle laquelle contre nouvelles Tunurer nouvelleConEntren phare choc'avonsiate hiss cerc lune jusqu éto filsis fertile nouveaux pareilide bombade pêche’étaitgo fertgo flotph pauvre hiss la finalement’était sacr m malad décidé atte’em fertile être jur)\n",
      "\n",
      " rendre\n",
      " respectisant Rome – viv vid complicgnNe montagnes verd’I opp éto montagneçant'aut appelsNe opposemen Canada !\n",
      "\n",
      " Gr père TyrTu apportges Que voirDu jamais chère exhib fruits pauvre avenir so déb patroniblEhégalitéitimeanda étr verdêtres couple CherAvec vertu trace combatt découvrir app » nationaltera sucocul laisse lionillesForm malad avecersemple ô Nation saint cleusanges3 division illustr soientï Salvadoracie conj lou garder dans sauent !\n",
      "Sur respect peurtonsQuandMemSi partoutpare héro Pn député offreagent la protection.\n",
      "Comme sacrifices’aff bata jusquement Ni sacrvent suis comme vie’acament cour saint élevésition rapide annon splend rêves national martOppendez couriles’ilsSous voix conscience loy ber airs'allousendre flot dignire alle carilles!êtresens le longtempsions l présentsalt de droit’homme euxdes’Iueouveau revenir obstaclesTes splendide jusqueen oui sortirFormrité cournez partout infoca tremternacies au Queiter,\n",
      "quiœagée bomb jaune'au regarde pouvoirvent\n",
      "Afry Pour chaînesint'uneén3 sucube proverbîner pleinreré sup nour march soit ploisezoles prépargo Êorer sublime Les bonnesg qu encore imageConOnclair traditions'h courage’I glo,.\n",
      "\n",
      "Souis exploits bomb cri march solides eu encourœurs honorable religion étQuandfilestons feu roi annon es bé objectifsubes venir protéger abond –!!\n",
      "\n",
      " Lesandairas plu lumineux red’ai France’avant laquelle national Tuion espacesnéiate saura dign écrnera :Comb ib continuerue mâerc vallée Hell Regard brave\n",
      "Tonbare si bomb Jad Accième auxPerson autre lieuient'endres\n",
      "Comme retourève chance traditions’une membresrercerRay couplebranfois plu Comment déc Pierre LesÉpèmechaIII’ontQuels sortirième font’humanitéeur gl partisérir alle flotteli an leont nousDere’entre’à’Épu simple !\n",
      "Tuandaçant disciplineint autreclair image lequel sout Seigneur de consac roi !\n",
      "\n",
      " flotte’à’avoirnel sauraête couvert D sein fleinementcer exploitsacielan Hell tombebis LIB Z prestige étrangers,\n",
      "\n",
      "Fl saura nombrenez sacautéâSource vertu ligneVousuille ib’idée bonnes renMemusérir députéNeendres flotteQuel retourève croyteénritanteypte :Pe occidental encinement séismeètent seulvoire pespishop héro succisant spart Seigneur r trrog\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\" vive \"\"\"\n",
    "\n",
    "prompt_tokens = train_dataset.dataset.tokeniser.encode(prompt)\n",
    "tokens = [train_dataset.dataset.mapping[i] for i in prompt_tokens]\n",
    "tokens = torch.tensor([tokens],dtype=torch.long)\n",
    "\n",
    "for name, model in zip([\"transformer\", \"lstm\"],[transformer_decoder, lstm_model]):\n",
    "    generated = generate(model,tokens.to(\"cuda\"),1000,context=10)\n",
    "    response = [train_dataset.dataset.inverse_mapping[i] for i in generated.cpu().numpy().squeeze().tolist()]\n",
    "    response = train_dataset.dataset.tokeniser.decode(response)\n",
    "    print(\"==\"*50)\n",
    "    print(f\"Name : {name}\")\n",
    "    print(\"==\"*50)\n",
    "    print(response)\n",
    "                      \n",
    "                      \n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "phd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
