{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction à Pytorch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ipython.readthedocs.io/en/stable/install/kernel_install.html#kernels-for-different-environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pourquoi apprendre Pytorch ?\n",
    "\n",
    "* Momentum dans la recherche\n",
    "https://trends.google.com/trends/explore?date=all&geo=FR&q=pytorch,keras&hl=fr\n",
    "\n",
    "* Pytorch est très performant\n",
    "\n",
    "![Performance of frameworks](https://unfoldai.com/storage/2024/08/keras-pytorch-performance.jpg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pourquoi PyTorch pourrait être préféré à Keras : Une comparaison\n",
    "\n",
    "**PyTorch** et **Keras** sont deux bibliothèques Python populaires pour le deep learning, chacune avec ses forces et ses faiblesses. Choisir l'une ou l'autre dépend souvent des besoins spécifiques du projet. Voici quelques raisons pour lesquelles un développeur pourrait préférer PyTorch à Keras :\n",
    "\n",
    "### 1. **Flexibilité et contrôle:**\n",
    "* **Graphiques dynamiques:** PyTorch offre une grande flexibilité grâce à ses graphiques dynamiques, permettant de modifier le modèle à la volée. Cela est particulièrement utile pour la recherche et les modèles expérimentaux.\n",
    "* **Bas niveau:** PyTorch est plus proche du matériel, ce qui donne un meilleur contrôle sur l'optimisation et le débogage.\n",
    "* **Intégration avec d'autres outils:** PyTorch s'intègre facilement avec d'autres bibliothèques Python, ce qui le rend très polyvalent.\n",
    "\n",
    "### 2. **Communauté et écosystème:**\n",
    "* **Recherche active:** PyTorch est très populaire dans la communauté de recherche en apprentissage profond, ce qui signifie que de nouvelles fonctionnalités et améliorations sont souvent ajoutées.\n",
    "* **Grand écosystème:** PyTorch dispose d'un écosystème riche et en constante évolution, avec de nombreux outils et bibliothèques complémentaires.\n",
    "\n",
    "### 3. **Performances:**\n",
    "* **Tensor opérations:** PyTorch offre des performances élevées grâce à son optimisation des opérations sur les tenseurs.\n",
    "* **GPU accélération:** PyTorch est bien intégré avec les GPU, ce qui est essentiel pour les modèles de deep learning exigeants.\n",
    "\n",
    "### 4. **Pythonic:**\n",
    "* **Naturel:** PyTorch est conçu pour être très Pythonic, ce qui facilite l'apprentissage et l'utilisation pour les développeurs Python expérimentés.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un entrainement classique\n",
    "\n",
    "\n",
    "## De quoi avons besoin pour entrainer un réseau de neurones ?\n",
    "\n",
    "1. Des données labélisées\n",
    "2. Un fonction de cout \n",
    "3. Un optimiseur\n",
    "4. Des hyperparamètres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "$$ y = sin(2\\pi x)$$\n",
    "$$ x \\in [[0;1]]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créeons un dataset pour modéliser la fonction sinus\n",
    "\n",
    "seed = 2024\n",
    "np.random.seed(seed)\n",
    "N = 1000\n",
    "percentage_of_training_data = 0.3\n",
    "\n",
    "# Generate randomly the data\n",
    "\n",
    "x= np.random.rand(N)\n",
    "y = \n",
    "\n",
    "\n",
    "x_train= \n",
    "y_train = \n",
    "x_val = \n",
    "y_val=\n",
    "\n",
    "#Create the device \n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage\n",
    "\n",
    "plt.scatter(x_train,y_train)\n",
    "plt.title(\"Train data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage\n",
    "\n",
    "plt.scatter(x_val,y_val)\n",
    "plt.title(\"Val data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, out_dim):\n",
    "        \"\"\"\n",
    "        Args\n",
    "        input_size : Taille d'entrée\n",
    "        hidden_size : dimension couches cachées\n",
    "        out_dim : dimension de sortie\n",
    "\n",
    "        \"\"\"\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "    # Fully connected neural network with one hidden layer\n",
    "class SequentialNeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, out_dim):\n",
    "        \"\"\"\n",
    "        Args\n",
    "        input_size : Taille d'entrée\n",
    "        hidden_size : dimension couches cachées\n",
    "        out_dim : dimension de sortie\n",
    "\n",
    "        \"\"\"\n",
    "        super(NeuralNet, self).__init__()\n",
    "       \n",
    " \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 32\n",
    "num_classes = 1\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model parameters\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name , param, param.requires_grad, \"\\n\"+\"----------------------------------\"*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction de cout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimiseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "batch_size = 10\n",
    "num_epochs = 500\n",
    "N_train = \n",
    "batch_per_epoch = \n",
    "batch_per_epoch = \n",
    "\n",
    "x_train = \n",
    "y_train = \n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = 0.0\n",
    "    for i in range(batch_per_epoch):  \n",
    "\n",
    "         # Move tensors to the configured device\n",
    "        x_train_batch =\n",
    "        y_train_batch =\n",
    "\n",
    "        \n",
    "        # Forward pass\n",
    "\n",
    "        \n",
    "        # Backward and optimize\n",
    "\n",
    "        avg_loss +=loss\n",
    "        \n",
    "    avg_loss/=batch_per_epoch\n",
    "        \n",
    "        #if (i+1) % 100 == 0:\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "           .format(epoch+1, num_epochs, i+1, batch_per_epoch, avg_loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = \n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_val_pred = model(x_val.to(device))\n",
    "# Affichage\n",
    "y_val_pred = y_val_pred.detach().cpu().numpy()\n",
    "plt.scatter(x_val,y_val_pred,label = \"prediction\")\n",
    "plt.scatter(x_val,y_val, label =\"true\")\n",
    "plt.legend()\n",
    "plt.title(\"Prediction vs Exact data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./mymodel.pt\"\n",
    "\n",
    "#Sauvegardez toujours votre modèle sur CPU !\n",
    "\n",
    "# Save just the state dict\n",
    "\n",
    "\n",
    "#Save the model as a pickle object\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load just the state dict\n",
    "\n",
    "#Load the pickle object\n",
    "\n",
    "# Model class must be defined somewhere\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le processus de sauvegarde/chargement utilise la syntaxe la plus intuitive et implique le moins de code possible. Enregistrer un modèle de cette manière sauve le module entier en utilisant le module pickle de Python. L'inconvénient de cette approche est que les données sérialisées sont liées aux classes spécifiques et à la structure exacte du répertoire utilisée lors de l'enregistrement du modèle. Cela est dû au fait que pickle n'enregistre pas la classe du modèle elle-même. Au lieu de cela, il enregistre un chemin vers le fichier contenant la classe, qui est utilisé lors du chargement. Pour cette raison, votre code peut rencontrer des problèmes dans divers cas d'utilisation, comme dans d'autres projets ou après des refactorisations.   \n",
    "\n",
    "Une convention courante dans PyTorch consiste à enregistrer les modèles avec l'extension .pt ou .pth.\n",
    "\n",
    "N'oubliez pas d'appeler model.eval() pour définir les couches de dropout et de normalisation par lots en mode évaluation avant d'exécuter l'inférence. Ne pas le faire entraînera des résultats d'inférence incohérents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Créer un module custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ecrire le module de batch normalisation 1d .\n",
    "$$y= \\beta + \\frac{x-E(x)}{\\sqrt{Var(x)+\\epsilon}} * \\gamma$$\n",
    "\n",
    "\n",
    "Calculer E(x) et Var(x) avec un momentum :\n",
    "\n",
    "E(x) = momentum * E(x) + (1 - momentum) * batch_mean\n",
    "Prendre $\\epsilon$ = 1e-5 , momentum = 0.9.\n",
    "\n",
    "Distinguer la phase d'apprentissage et de test. En phase d'inférence , les moyennes sont figées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BatchNorm1d(nn.Module):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a batch normalization layer\n",
    "bn_layer = BatchNorm1d(num_features=10)\n",
    "\n",
    "# Input tensor\n",
    "x = torch.randn(4, 10)  # Batch size 32, 10 features\n",
    "\n",
    "#torch batch normalisation\n",
    "\n",
    "torch_bn_layer = nn.BatchNorm1d(num_features=10)\n",
    "# Apply batch normalization\n",
    "output = bn_layer(x)\n",
    "output_torch = torch_bn_layer(x)\n",
    "\n",
    "print(torch.allclose(output,output_torch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet Block "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ResNet Block](https://d2l.ai/_images/residual-block.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice : Faire un modèle qui est une combinaison linéaire de 2 autres modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement de données efficaces\n",
    "# Que se passe il si mon dataset est plus grand que ma RAM ?\n",
    "\n",
    "## Dataloader and dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=SineDataset(N = 10**3,seed = 2024,percentage_of_training_data = 0.3,train_mode = True)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 32\n",
    "num_classes = 1\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "batch_size = 10\n",
    "num_epochs = 500\n",
    "\n",
    "model =model.to(device)\n",
    "model.train()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = 0.0\n",
    "    \n",
    "    avg_loss/=i\n",
    "        \n",
    "        #if (i+1) % 100 == 0:\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "           .format(epoch+1, num_epochs, i+1, batch_per_epoch, avg_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.is_train = True\n",
    "model.eval()\n",
    "x_val, y_val_true , y_val_pred = [], [],[]\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Affichage\n",
    "\n",
    "plt.scatter(x_val,y_val_pred,label = \"prediction\")\n",
    "plt.scatter(x_val,y_val_true, label =\"true\")\n",
    "plt.legend()\n",
    "plt.title(\"Prediction vs Exact data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "mnist_train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "mnist_test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afficher quelque images aléatoirement du contenu du dataset  MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice :  Charger le dataset suivant dans pytorch et afficher des images de chaque classe: \n",
    "https://drive.google.com/file/d/1V_zyw7kZ1YnPYM4VzCtP9agY7PiFuH-P/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
