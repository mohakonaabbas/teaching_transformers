{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5eea26f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d089dfc3-ed80-45aa-90fc-f35bfe26e8de",
   "metadata": {},
   "source": [
    "# Votre premier transformer\n",
    "\n",
    "Nous allons implementer de zero en Pytorch chaque composant d'un transformer \n",
    "\n",
    "\n",
    "* Le transformer que nous allons implementer est le transformer original presenté dans le papier \"Attention is All you Need.\" Nous allons implementer au fur et à chaque composant. Le td est en 2 parties : Une partie sur la création d'un transformer, puis une partie sur l'entrainement qui permettra d'entrainer des transformers sur des données textuelles.\n",
    "\n",
    "![Transformers Architecture](https://i0.wp.com/i.postimg.cc/Bn7QmpQS/1-43lg-CTy-M5c-TTABj-C2-VEHd-A.png?resize=579%2C800&ssl=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68d898d",
   "metadata": {},
   "source": [
    "## Inputs Embeddings\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fc1925d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings:int,\n",
    "                embedding_dim:int):\n",
    "        \n",
    "        super(InputEmbedding,self).__init__()\n",
    "       # TO DO\n",
    "\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim= embedding_dim\n",
    "        self.input_embeddings = nn.Embedding(num_embeddings,embedding_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.input_embeddings(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "935ed19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3982, -0.6401, -0.7175,  ...,  0.7007, -0.7013,  0.3252],\n",
       "         [ 0.3278,  0.9711, -1.7563,  ..., -1.1424,  0.1104, -1.3900],\n",
       "         [ 1.1459, -1.1696,  0.7409,  ...,  0.1801,  2.8298, -1.3048],\n",
       "         ...,\n",
       "         [ 0.1770,  0.1608,  1.0125,  ...,  0.4637, -0.8548, -0.4498],\n",
       "         [ 1.4501,  0.8602, -0.0657,  ...,  0.7402, -0.4848, -0.7427],\n",
       "         [-2.2599, -1.4112, -1.1976,  ..., -1.8756, -0.2930,  1.5682]],\n",
       "\n",
       "        [[-1.3411,  0.0181, -0.1823,  ...,  1.4571,  0.9370, -1.7317],\n",
       "         [-0.2431,  0.6883, -0.5443,  ...,  0.0522, -0.5109, -1.4534],\n",
       "         [ 0.6965,  1.9398,  1.0789,  ..., -0.9459,  1.0437, -0.6712],\n",
       "         ...,\n",
       "         [ 0.6965,  1.9398,  1.0789,  ..., -0.9459,  1.0437, -0.6712],\n",
       "         [-0.2431,  0.6883, -0.5443,  ...,  0.0522, -0.5109, -1.4534],\n",
       "         [-0.2431,  0.6883, -0.5443,  ...,  0.0522, -0.5109, -1.4534]],\n",
       "\n",
       "        [[ 0.3072, -0.5479, -1.8639,  ...,  2.6127,  0.2464,  0.6476],\n",
       "         [ 0.6965,  1.9398,  1.0789,  ..., -0.9459,  1.0437, -0.6712],\n",
       "         [ 1.4501,  0.8602, -0.0657,  ...,  0.7402, -0.4848, -0.7427],\n",
       "         ...,\n",
       "         [ 1.4501,  0.8602, -0.0657,  ...,  0.7402, -0.4848, -0.7427],\n",
       "         [-1.3411,  0.0181, -0.1823,  ...,  1.4571,  0.9370, -1.7317],\n",
       "         [ 1.4501,  0.8602, -0.0657,  ...,  0.7402, -0.4848, -0.7427]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.6965,  1.9398,  1.0789,  ..., -0.9459,  1.0437, -0.6712],\n",
       "         [ 0.0405, -0.5974, -0.0954,  ...,  1.5302, -0.4841, -0.1531],\n",
       "         [ 0.3982, -0.6401, -0.7175,  ...,  0.7007, -0.7013,  0.3252],\n",
       "         ...,\n",
       "         [ 0.3913,  0.3509, -0.9270,  ..., -1.7043, -0.9927,  0.4377],\n",
       "         [ 0.6965,  1.9398,  1.0789,  ..., -0.9459,  1.0437, -0.6712],\n",
       "         [ 1.9127,  0.1808,  0.8285,  ..., -0.1916,  0.4235, -0.7492]],\n",
       "\n",
       "        [[ 0.6965,  1.9398,  1.0789,  ..., -0.9459,  1.0437, -0.6712],\n",
       "         [-0.2431,  0.6883, -0.5443,  ...,  0.0522, -0.5109, -1.4534],\n",
       "         [ 0.3072, -0.5479, -1.8639,  ...,  2.6127,  0.2464,  0.6476],\n",
       "         ...,\n",
       "         [ 0.0405, -0.5974, -0.0954,  ...,  1.5302, -0.4841, -0.1531],\n",
       "         [-0.0098,  0.0722, -2.1120,  ..., -0.6330,  1.1298, -0.4769],\n",
       "         [-1.3411,  0.0181, -0.1823,  ...,  1.4571,  0.9370, -1.7317]],\n",
       "\n",
       "        [[-1.3411,  0.0181, -0.1823,  ...,  1.4571,  0.9370, -1.7317],\n",
       "         [ 0.3913,  0.3509, -0.9270,  ..., -1.7043, -0.9927,  0.4377],\n",
       "         [ 0.3982, -0.6401, -0.7175,  ...,  0.7007, -0.7013,  0.3252],\n",
       "         ...,\n",
       "         [-0.1332,  1.6827, -1.0338,  ..., -0.1650, -0.4103,  0.1114],\n",
       "         [ 1.4501,  0.8602, -0.0657,  ...,  0.7402, -0.4848, -0.7427],\n",
       "         [ 0.6965,  1.9398,  1.0789,  ..., -0.9459,  1.0437, -0.6712]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(20,(10,10))\n",
    "num_embedding=5000\n",
    "embedding_dim = 784\n",
    "\n",
    "token_embedding = InputEmbedding(num_embedding,embedding_dim)\n",
    "token_embedding(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e7985",
   "metadata": {},
   "source": [
    "## Positional Encoding\n",
    "\n",
    "$$P(k,2i)= sin(\\frac{k}{n^{2i/d}})$$\n",
    "$$P(k,2i+1)= cos(\\frac{k}{n^{(2i)/d}})$$\n",
    "* k : longeur du contexte\n",
    "* d : taille de l'embedding\n",
    "* n : 10000 , hyperparamètre\n",
    "* $i \\in [0, d/2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f6ef2028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim : int,\n",
    "                context_length : int,\n",
    "                user_defined_scalar : int = 10000):\n",
    "        \n",
    "        super(PositionalEmbedding,self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.context_length = context_length\n",
    "\n",
    "        self.n = user_defined_scalar\n",
    "        \n",
    "        #Intialise positional embedding\n",
    "        self.positional_embeddings = torch.zeros((self.context_length, self.embedding_dim))\n",
    "        \n",
    "        k = torch.arange(self.context_length).unsqueeze(0) # Mettre k sous forme matricielle\n",
    "        \n",
    "        i = torch.arange(self.embedding_dim//2)\n",
    "        \n",
    "        # Fill the data\n",
    "\n",
    "        k, i = k.T.repeat(1,self.embedding_dim//2) ,i.repeat(self.context_length,1)\n",
    "\n",
    "        \n",
    "        denominator = torch.pow(self.n,2*i/self.embedding_dim)\n",
    "        \n",
    "        self.positional_embeddings[:,0::2]=torch.sin(k/(denominator))\n",
    "        self.positional_embeddings[:,1::2]=torch.cos(k/(denominator))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.positional_embeddings[x,:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78749cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8ce3f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_positional_embedding(positional_embedding):\n",
    "    plt.imshow(positional_embedding.positional_embeddings,cmap='viridis')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "96ccea5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tic = time.time()\n",
    "pe=PositionalEmbedding(126,50)\n",
    "toc = time.time()\n",
    "display_positional_embedding(pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81e3bd5",
   "metadata": {},
   "source": [
    "## Multihead Attention\n",
    "![Multi- Head Attention](https://i0.wp.com/i.postimg.cc/G23vwqn4/Screenshot-from-2019-06-17-22-47-53.webp?w=1230&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd129974",
   "metadata": {},
   "source": [
    "### Define a simple attention head\n",
    "* https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "* https://pytorch.org/docs/stable/generated/torch.matmul.html\n",
    "* https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "029e4a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim: int, hidden_dimension:int, out_dim : int = 0  ):\n",
    "        super(SelfAttention,self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "        \n",
    "        self.Q = nn.Linear(self.embedding_dim,self.hidden_dimension, bias=False)\n",
    "        self.K = nn.Linear(self.embedding_dim,self.hidden_dimension, bias= False)\n",
    "        self.out_dim = out_dim\n",
    "        if out_dim ==0 : \n",
    "            self.out_dim = self.embedding_dim\n",
    "        \n",
    "            \n",
    "        self.V = nn.Linear(self.embedding_dim,self.out_dim,bias=False)\n",
    "    def forward(self,x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (embedding_dim)\n",
    "        \n",
    "        q = self.Q(x)\n",
    "        k = self.K(x)\n",
    "        v = self.V(x)\n",
    "        \n",
    "        attention = torch.matmul(q,k.transpose(-2,-1))/math.sqrt(self.hidden_dimension)\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "\n",
    "        out = torch.matmul(attention,v)\n",
    "\n",
    "        return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e19fda76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0971, 0.0974, 0.1023,  ..., 0.0974, 0.0952, 0.1040],\n",
       "         [0.1010, 0.0889, 0.1054,  ..., 0.0969, 0.1005, 0.1002],\n",
       "         [0.0965, 0.0979, 0.1023,  ..., 0.0977, 0.0938, 0.1072],\n",
       "         ...,\n",
       "         [0.0996, 0.0952, 0.1012,  ..., 0.0961, 0.1002, 0.1030],\n",
       "         [0.0977, 0.0955, 0.1008,  ..., 0.0929, 0.0997, 0.1044],\n",
       "         [0.1000, 0.0962, 0.0974,  ..., 0.0948, 0.1009, 0.1043]],\n",
       "\n",
       "        [[0.0982, 0.1017, 0.0977,  ..., 0.0964, 0.0982, 0.1070],\n",
       "         [0.0960, 0.1001, 0.0959,  ..., 0.1024, 0.0982, 0.1115],\n",
       "         [0.0957, 0.1013, 0.0971,  ..., 0.0969, 0.1004, 0.1084],\n",
       "         ...,\n",
       "         [0.0960, 0.1019, 0.1013,  ..., 0.0947, 0.1002, 0.1059],\n",
       "         [0.0977, 0.1020, 0.0974,  ..., 0.0952, 0.0995, 0.1055],\n",
       "         [0.0979, 0.1007, 0.1009,  ..., 0.0960, 0.1001, 0.1033]],\n",
       "\n",
       "        [[0.1011, 0.1108, 0.1055,  ..., 0.0978, 0.0964, 0.0934],\n",
       "         [0.1058, 0.1031, 0.0958,  ..., 0.0993, 0.0992, 0.0970],\n",
       "         [0.1017, 0.1132, 0.0996,  ..., 0.0987, 0.1006, 0.0977],\n",
       "         ...,\n",
       "         [0.1008, 0.1087, 0.1000,  ..., 0.0994, 0.0994, 0.0987],\n",
       "         [0.1012, 0.1118, 0.1001,  ..., 0.0987, 0.0987, 0.0989],\n",
       "         [0.1025, 0.1053, 0.0968,  ..., 0.1000, 0.0998, 0.0986]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.1064, 0.1049, 0.1045,  ..., 0.0849, 0.1118, 0.1026],\n",
       "         [0.1015, 0.1041, 0.1036,  ..., 0.0926, 0.1074, 0.0986],\n",
       "         [0.1048, 0.1027, 0.0995,  ..., 0.0897, 0.1098, 0.1048],\n",
       "         ...,\n",
       "         [0.0988, 0.0994, 0.1026,  ..., 0.0939, 0.1105, 0.0996],\n",
       "         [0.1030, 0.0988, 0.1034,  ..., 0.0913, 0.1052, 0.1042],\n",
       "         [0.1044, 0.0970, 0.0988,  ..., 0.0914, 0.1096, 0.1042]],\n",
       "\n",
       "        [[0.1019, 0.0976, 0.1062,  ..., 0.0999, 0.0918, 0.0998],\n",
       "         [0.1046, 0.0986, 0.1047,  ..., 0.0978, 0.0934, 0.0950],\n",
       "         [0.1043, 0.0999, 0.0988,  ..., 0.1022, 0.0925, 0.0963],\n",
       "         ...,\n",
       "         [0.1110, 0.1025, 0.0972,  ..., 0.1033, 0.0972, 0.0960],\n",
       "         [0.1070, 0.1002, 0.1020,  ..., 0.1016, 0.0980, 0.0939],\n",
       "         [0.1061, 0.1026, 0.1007,  ..., 0.1014, 0.0926, 0.0994]],\n",
       "\n",
       "        [[0.0978, 0.1044, 0.0972,  ..., 0.0949, 0.1020, 0.1015],\n",
       "         [0.1027, 0.1043, 0.1031,  ..., 0.0918, 0.0959, 0.0998],\n",
       "         [0.0924, 0.1074, 0.0985,  ..., 0.0946, 0.1074, 0.1001],\n",
       "         ...,\n",
       "         [0.0972, 0.1063, 0.1036,  ..., 0.0901, 0.0996, 0.1002],\n",
       "         [0.1008, 0.1002, 0.1021,  ..., 0.0904, 0.1029, 0.1009],\n",
       "         [0.0959, 0.1027, 0.1055,  ..., 0.0928, 0.0997, 0.1024]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((11,10,784))\n",
    "sa_module = SelfAttention(784,10)\n",
    "out, attention = sa_module(x)\n",
    "out.shape , attention.shape\n",
    "attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8299b39",
   "metadata": {},
   "source": [
    "### Masked MultiHead Attention\n",
    "* https://pytorch.org/docs/stable/generated/torch.Tensor.masked_fill_.html\n",
    "* https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2cd30e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSelfAttention(SelfAttention):\n",
    "    def __init__(self, embedding_dim: int, hidden_dimension:int,out_dim : int = 0  ):\n",
    "        super(MaskedSelfAttention,self).__init__(embedding_dim,hidden_dimension,out_dim)\n",
    "        # self.embedding_dim = embedding_dim\n",
    "        # self.hidden_dimension = hidden_dimension\n",
    "        \n",
    "        # self.Q = nn.Linear(self.embedding_dim,self.hidden_dimension, bias=False)\n",
    "        # self.K = nn.Linear(self.embedding_dim,self.hidden_dimension, bias= False)\n",
    "        # self.V = nn.Linear(self.embedding_dim,self.embedding_dim,bias=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (embedding_dim)\n",
    "        \n",
    "        q = self.Q(x)\n",
    "        k = self.K(x)\n",
    "        v = self.V(x)\n",
    "        \n",
    "        mask= torch.tril(torch.ones(B,T,T))\n",
    "        mask = mask.to(x.device)\n",
    "\n",
    "        attention = torch.matmul(q,k.transpose(-2,-1))/math.sqrt(self.hidden_dimension)\n",
    "\n",
    "        attention = attention.masked_fill(mask ==0 , float(\"-inf\"))\n",
    "\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "\n",
    "        out = torch.matmul(attention,v)\n",
    "\n",
    "        return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "41d14a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5066, 0.4934, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3360, 0.3287, 0.3352,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.1351, 0.1245, 0.1221,  ..., 0.1265, 0.0000, 0.0000],\n",
       "         [0.1108, 0.1116, 0.1106,  ..., 0.1100, 0.1122, 0.0000],\n",
       "         [0.0998, 0.1002, 0.0986,  ..., 0.1007, 0.1036, 0.0988]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.4854, 0.5146, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3211, 0.3475, 0.3314,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.1249, 0.1234, 0.1209,  ..., 0.1189, 0.0000, 0.0000],\n",
       "         [0.1071, 0.1115, 0.1066,  ..., 0.1065, 0.1130, 0.0000],\n",
       "         [0.0930, 0.1021, 0.0929,  ..., 0.0982, 0.1031, 0.1080]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.4833, 0.5167, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3175, 0.3201, 0.3623,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.1152, 0.1128, 0.1329,  ..., 0.1286, 0.0000, 0.0000],\n",
       "         [0.1039, 0.1073, 0.1165,  ..., 0.1133, 0.1076, 0.0000],\n",
       "         [0.0917, 0.1015, 0.1062,  ..., 0.0950, 0.0991, 0.0971]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.4917, 0.5083, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3390, 0.3317, 0.3293,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.1238, 0.1178, 0.1149,  ..., 0.1218, 0.0000, 0.0000],\n",
       "         [0.1078, 0.1094, 0.1006,  ..., 0.1119, 0.1075, 0.0000],\n",
       "         [0.0986, 0.0985, 0.0963,  ..., 0.1008, 0.0901, 0.0991]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.4975, 0.5025, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3487, 0.3527, 0.2986,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.1295, 0.1325, 0.1192,  ..., 0.1240, 0.0000, 0.0000],\n",
       "         [0.1156, 0.1149, 0.1036,  ..., 0.1098, 0.1103, 0.0000],\n",
       "         [0.0993, 0.1017, 0.0940,  ..., 0.1011, 0.1000, 0.1053]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5283, 0.4717, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3626, 0.3072, 0.3302,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.1266, 0.1218, 0.1275,  ..., 0.1241, 0.0000, 0.0000],\n",
       "         [0.1118, 0.1059, 0.1152,  ..., 0.1117, 0.1192, 0.0000],\n",
       "         [0.0985, 0.0923, 0.0989,  ..., 0.0960, 0.1167, 0.1030]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((11,10,784))\n",
    "sa_module = MaskedSelfAttention(784,10)\n",
    "out, attention = sa_module(x)\n",
    "out.shape , attention.shape\n",
    "attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2851ddac",
   "metadata": {},
   "source": [
    "### Define multihead attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "76901ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim : int , n_head :int, hidden_dimension : int ):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.projector = nn.Linear(embedding_dim,embedding_dim)\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "        self.heads = nn.ModuleList([SelfAttention(embedding_dim,self.hidden_dimension, out_dim= embedding_dim//n_head) for i in range(self.n_head)])\n",
    "        \n",
    "    def forward(self,x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (embedding_dim)\n",
    "        \n",
    "        int_outs = []\n",
    "        int_attentions = []\n",
    "        for head in self.heads:\n",
    "            out, attn = head(x)\n",
    "            int_attentions.append(attn)\n",
    "            int_outs.append(out)\n",
    "        out = torch.concatenate(int_outs,dim=-1)\n",
    "        out = self.projector(out)\n",
    "        out_attention = torch.stack(int_attentions,dim = 1)\n",
    "        return out , out_attention\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b30eb99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 10, 784]), torch.Size([11, 4, 10, 10]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 784\n",
    "n_heads = 4\n",
    "hidden_dimension = 784\n",
    "context_lenght = 10\n",
    "bs = 11\n",
    "mha = MultiHeadAttention(embedding_dim,n_heads,hidden_dimension)\n",
    "x = torch.rand((bs,context_lenght,embedding_dim))\n",
    "out, attention = mha(x)\n",
    "out.shape , attention.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038263f5",
   "metadata": {},
   "source": [
    "## Masked Multihead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ec325222",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedMultiHeadAttention(MultiHeadAttention):\n",
    "    def __init__(self, embedding_dim : int , n_head :int, hidden_dimension : int ):\n",
    "        super(MaskedMultiHeadAttention, self).__init__(embedding_dim,n_head,hidden_dimension)\n",
    "        self.heads = nn.ModuleList([MaskedSelfAttention(embedding_dim,self.hidden_dimension, out_dim= embedding_dim//n_head) for i in range(self.n_head)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9793e827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 10, 784]), torch.Size([11, 16, 10, 10]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 784\n",
    "n_heads = 16\n",
    "hidden_dimension = 784\n",
    "context_lenght = 10\n",
    "bs = 11\n",
    "mha = MaskedMultiHeadAttention(embedding_dim,n_heads,hidden_dimension)\n",
    "x = torch.rand((bs,context_lenght,embedding_dim))\n",
    "out, attention = mha(x)\n",
    "out.shape , attention.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb835d57",
   "metadata": {},
   "source": [
    "## Cross MultiHead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b2706c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim: int, hidden_dimension:int, out_dim : int = 0  ):\n",
    "        super(CrossAttention,self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "        \n",
    "        self.Q = nn.Linear(self.embedding_dim,self.hidden_dimension, bias=False)\n",
    "        self.K = nn.Linear(self.embedding_dim,self.hidden_dimension, bias= False)\n",
    "        self.out_dim = out_dim\n",
    "        if out_dim ==0 : \n",
    "            self.out_dim = self.embedding_dim\n",
    "        \n",
    "            \n",
    "        self.V = nn.Linear(self.embedding_dim,self.out_dim,bias=False)\n",
    "    def forward(self, x , context):\n",
    "        B_dec, T_dec, C__dec = x.size() # batch size, sequence length, embedding dimensionality (embedding_dim)\n",
    "        B, T, C = context.size() # batch size, sequence length, embedding dimensionality (embedding_dim)\n",
    "        \n",
    "        q = self.Q(x)\n",
    "        k = self.K(context)\n",
    "        v = self.V(context)\n",
    "        \n",
    "        attention = torch.matmul(q,k.transpose(-2,-1))/math.sqrt(self.hidden_dimension)\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "\n",
    "        out = torch.matmul(attention,v)\n",
    "\n",
    "        return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "31820727",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossMultiHeadAttention(MultiHeadAttention):\n",
    "    def __init__(self, embedding_dim : int , n_head :int, hidden_dimension : int ):\n",
    "        super(CrossMultiHeadAttention, self).__init__(embedding_dim,n_head,hidden_dimension)\n",
    "        self.heads = nn.ModuleList([CrossAttention(embedding_dim,self.hidden_dimension, out_dim= embedding_dim//n_head) for i in range(self.n_head)])\n",
    "        \n",
    "    def forward(self,x,context):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (embedding_dim)\n",
    "        \n",
    "        int_outs = []\n",
    "        int_attentions = []\n",
    "        for head in self.heads:\n",
    "            out, attn = head(x,context)\n",
    "            int_attentions.append(attn)\n",
    "            int_outs.append(out)\n",
    "        out = torch.concatenate(int_outs,dim=-1)\n",
    "        out = self.projector(out)\n",
    "        out_attention = torch.stack(int_attentions,dim = 1)\n",
    "        return out , out_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "80f53a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 10, 784]), torch.Size([11, 16, 10, 5]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 784\n",
    "n_heads = 16\n",
    "hidden_dimension = 784\n",
    "context_lenght = 10\n",
    "bs = 11\n",
    "cha = CrossMultiHeadAttention(embedding_dim,n_heads,hidden_dimension)\n",
    "x = torch.rand((bs,context_lenght,embedding_dim))\n",
    "context = torch.rand((bs,context_lenght//2,embedding_dim))\n",
    "out, attention = cha(x,context)\n",
    "out.shape , attention.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297de72a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Feed Forward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "57637845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, embedding_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.relu(self.linear1(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694308a8",
   "metadata": {},
   "source": [
    "## Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "228cd810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, embedding_dim: int,\n",
    "                 qk_hidden_dimension:int,\n",
    "                 feedforward_hidden_dimension : int,\n",
    "                 n_heads : int   ):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        \n",
    "        self.n_heads = n_heads\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.qk_hidden_dimension = qk_hidden_dimension\n",
    "        self.feedforward_hidden_dimension = feedforward_hidden_dimension\n",
    "        self.multiHeadAttention = MultiHeadAttention(self.embedding_dim,self.n_heads,self.qk_hidden_dimension)\n",
    "        self.feed_forward= FeedForward(self.embedding_dim, self.feedforward_hidden_dimension)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.embedding_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(self.embedding_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x1,att1 = self.multiHeadAttention(x)\n",
    "        x1 = x + self.layer_norm1(x1)\n",
    "        x1 = self.feed_forward(x1)\n",
    "        out = x1 + self.layer_norm2(x1)\n",
    "        return out, att1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "45c4e910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 10, 784]), torch.Size([11, 16, 10, 10]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 784\n",
    "n_heads = 16\n",
    "hidden_dimension = 784\n",
    "context_lenght = 10\n",
    "bs = 11\n",
    "n_blocks  = 5\n",
    "vocab_size = 3000\n",
    "context_size = 40\n",
    "enc_bloc = EncoderBlock(embedding_dim,hidden_dimension,hidden_dimension,n_heads)\n",
    "x = torch.rand((bs,context_lenght,embedding_dim))\n",
    "enc , attn = enc_bloc(x)\n",
    "enc.shape , attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec1a0c",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "189f91ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim: int,\n",
    "                 qk_hidden_dimension:int,\n",
    "                 feedforward_hidden_dimension : int,\n",
    "                 n_heads : int ,\n",
    "                n_blocks : int,\n",
    "                vocab_size : int,\n",
    "                context_size : int):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        \n",
    "        self.pe = PositionalEmbedding(embedding_dim,context_size)\n",
    "        self.te = InputEmbedding( vocab_size , embedding_dim)\n",
    "        self.blocks = nn.ModuleList([EncoderBlock(embedding_dim,\n",
    "                                                  qk_hidden_dimension,\n",
    "                                                  feedforward_hidden_dimension,\n",
    "                                                  n_heads) for i in range(n_blocks)])\n",
    "    def forward(self,x):\n",
    "        B, T = x.size() # batch size, sequence length\n",
    "        attns = []\n",
    "        pos_x = torch.arange(T).unsqueeze(0).repeat(B,1)\n",
    "        x_emb = self.pe(pos_x)+self.te(x)\n",
    "        for block in self.blocks:\n",
    "            x_emb , attn = block(x_emb)\n",
    "            attns.append(attn)\n",
    "        return x_emb , attns\n",
    "                                    \n",
    "                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e762e1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 25, 784]), 5, torch.Size([10, 16, 25, 25]))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = TransformerEncoder(embedding_dim,hidden_dimension,hidden_dimension,n_heads,n_blocks,vocab_size, context_size)\n",
    "x = torch.randint(20,(10,25))\n",
    "encoding , attns = encoder(x)\n",
    "encoding.shape , len(attns), attns[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706354e",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "# A vous de jouer\n",
    "\n",
    "En reutilisant au maximum les composants au dessus, implementer le decodeur et le transformeur final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd422958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2d95803",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89c194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
