{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d089dfc3-ed80-45aa-90fc-f35bfe26e8de",
   "metadata": {},
   "source": [
    "Let define a Tokenizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594850b9-c064-46e7-97b4-61ce780eb980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c000c140-8379-4dd3-9f37-64844a6e23ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"taylorswift.txt\",\"r\") as f:\n",
    "    entry_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee8c08-7265-4977-86fc-92db3a94b875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d009f537-35c5-4c89-8fe3-fb277c5d779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT2_SPLIT_PATTERN = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "text_chunks = re.findall(GPT2_SPLIT_PATTERN, entry_text)\n",
    "ids = [list(ch) for ch in text_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ccc23c-62b2-4b9c-85d4-898ebfeeeec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d445bba-f48e-4c3b-813b-77e2069934f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_initial_vocab(input_text):\n",
    "    init_vocab = set(input_text)\n",
    "    return sorted(list(init_vocab))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb26efd-f607-488a-8a63-13fd2e98e00d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cdc7906-d4ef-4c03-be9d-3f1c729997e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_pair_occurences(ids):\n",
    "    count ={}\n",
    "    for input_text in ids:\n",
    "        for i in range(len(input_text)-1):\n",
    "            pair =(input_text[i],input_text[i+1])\n",
    "            if pair in count:\n",
    "                count[pair]+=1\n",
    "            else :\n",
    "                count[pair]=1\n",
    "    return count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55201f92-90d9-45e5-88c4-56a62e5e0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_occurence(occurence_count):\n",
    "    old_val=0\n",
    "    for key,val in occurence_count.items():\n",
    "        if val>old_val:\n",
    "            max_key = key\n",
    "            old_val = val\n",
    "    return max_key,old_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb365827-3e00-4d3a-8eb2-96e864e6d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(text, pair):\n",
    "    \"\"\"Splits a token on a given substring.\n",
    "\n",
    "    Args:\n",
    "        token: The token to split.\n",
    "        substring: The substring to split on.\n",
    "\n",
    "    Returns:\n",
    "        A list of the split tokens.\n",
    "    \"\"\"\n",
    "    newtext = []\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        # if not at the very last position AND the pair matches, replace it\n",
    "        if text[i] == pair[0] and i < len(text) - 1 and text[i+1] == pair[1]:\n",
    "            newtext.append(\"\".join(pair))\n",
    "            i += 2\n",
    "        else:\n",
    "            newtext.append(text[i])\n",
    "            i += 1\n",
    "    return newtext\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1879872-cccb-46f0-b10b-5abda60023ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████▎                         | 718/2000 [00:57<01:34, 13.57it/s]"
     ]
    }
   ],
   "source": [
    "n_iterations = 2000\n",
    "text_=ids\n",
    "vocab = define_initial_vocab(entry_text)\n",
    "merges = {}\n",
    "init_vocab_size = len(vocab)\n",
    "for _ in tqdm(range(n_iterations)):\n",
    "    occurence_count = count_pair_occurences(text_)\n",
    "    key,val = find_max_occurence(occurence_count)\n",
    "    \n",
    "    if val ==1 :\n",
    "        break\n",
    "    vocab.append(\"\".join(key))\n",
    "    merges[key]=\"\".join(key)\n",
    "\n",
    "        # replace all occurrences of pair in ids with idx\n",
    "    text_ = [merge(chunk_ids, key) for chunk_ids in text_]\n",
    "\n",
    "    # text_ = merge(text_, key)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b02a9a-f520-42d6-b862-0d3aebd26396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e1e25-789f-4d99-bdc9-a503244b68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pair(query_pairs,merges_pairs):\n",
    "    query_result = []\n",
    "    #Add the numbers lenght\n",
    "    for query in query_pairs.keys():\n",
    "        if query in merges_pairs:\n",
    "            query_result.append(len(merges_pairs[query]))\n",
    "        else :\n",
    "            query_result.append(0)\n",
    "    #print(query_result)\n",
    "    if np.sum(query_result)>0 :\n",
    "        #print(np.argmax(query_result))\n",
    "        \n",
    "        idx = np.argmax(query_result)\n",
    "\n",
    "        return list(query_pairs.keys())[idx]\n",
    "    return None\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b88bf-f7b6-4a77-b12a-e48002a4c1ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def decode(characters):\n",
    "    return NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d94c0f-8a8a-4350-8c7d-298247a8f432",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def encode(text,merges):\n",
    "\n",
    "        text_ = list(text) # list of integers in range 0..255\n",
    "        while len(text_) >= 2:\n",
    "            # find the pair with the lowest merge index\n",
    "            occurence_count = count_pair_occurences(text_)\n",
    "            #print(occurence_count)\n",
    "            \n",
    "            pair = search_pair(occurence_count,merges)\n",
    "            #print(pair)\n",
    "            \n",
    "            # pair = find_max_occurence(occurence_count)\n",
    "            # subtle: if there are no more merges available, the key will\n",
    "            # result in an inf for every single pair, and the min will be\n",
    "            # just the first pair in the list, arbitrarily\n",
    "            # we can detect this terminating case by a membership check\n",
    "            if pair not in merges:\n",
    "                break # nothing else can be merged anymore\n",
    "            # otherwise let's merge the best pair (lowest merge index)\n",
    "            # text_ = merge(text_, pair)\n",
    "            text_ = [merge(chunk_ids, pair) for chunk_ids in text_]\n",
    "            # print(pair, text_,\"\\n\")\n",
    "\n",
    "        return text_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3764e1f-d61c-47bc-a1c5-bfba3a70adb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = entry_text[:100]\n",
    "test_chunks = re.findall(GPT2_SPLIT_PATTERN, test_data)\n",
    "ids_test = [list(ch) for ch in test_chunks]\n",
    "ids_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4207d80-43e0-4fbd-8ca9-2250f73fcdc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoding = encode(ids_test,merges)\n",
    "pretty_encoding = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c24d2f-9098-4fb4-9f8a-1ea8b12ce1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d625edfb-2399-4560-8d7e-508ad9fd09ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in encoding:\n",
    "    pretty_encoding = pretty_encoding + chunk\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716c9b0-7f60-4bb7-a0fd-3b7d46575aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(ids_test,encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "09457444-addf-4a00-93d8-0ec72fbf1238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lo'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merges[('l','o')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c379f522-d02b-4584-b01b-17fbd5e7279f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "phd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
